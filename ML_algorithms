import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

X = 2 * np.random.rand(100, 1)
X_b = np.c_[np.ones((100,1)), X]
y = 4 + 3 * X + np.random.randn(100, 1)

def lin_reg(X, Y):
    
    #least square linear regression
    
    m = (len(X)*np.dot(X,Y)-(np.sum(X)*np.sum(Y)))/((len(X)*np.sum([num**2 for num in X]))-(np.sum(X)**2))
    b = (np.sum(Y) - m*np.sum(X))/len(X)
    
    return [float(m)*x+b for x in X]
    
    
    
def lin_reg_GD(X, Y, learning_rate, n_iterations):
    
    
    X_b = np.c_[np.ones((100,1)), X] #add X0 to X vector
    m = len(X)
    
    #Randomly Initialize theta
    theta = np.random.randn(2,1)

    #determine theta values iteratively
    for iteration in range(n_iterations):
        gradients = 2/m * X_b.T.dot(X_b.dot(theta)-y)
        theta = theta - learning_rate*gradients 
    
    return theta
    
